from urllib.request import urlopen, Request
from urllib.error import URLError, HTTPError
import ssl
import certifi
import os
import json
import sys
import time
from datetime import datetime, timezone
import argparse

API_URL = "https://uselessfacts.jsph.pl/random.json?language=en"
TIMEOUT = 10  # ç§’
RETRIES = 1
QUOTES_FILE = "quotes.json"  # æœ¬æ©Ÿå„²å­˜æª”æ¡ˆï¼ˆJSON æ ¼å¼ï¼‰


# --------- Persistence (JSON) ---------
def load_facts(filename: str = QUOTES_FILE):
    """è¼‰å…¥æœ¬æ©Ÿå·²å„²å­˜çš„äº‹å¯¦åˆ—è¡¨ã€‚

    çµæ§‹ï¼šlist[{
        "text": str,
        "source": Optional[str],
        "added_at": ISO8601 datetime string (UTC)
    }]
    è‹¥æª”æ¡ˆä¸å­˜åœ¨æˆ–æ ¼å¼éŒ¯èª¤ï¼Œå›å‚³ç©º listã€‚
    """
    if not os.path.exists(filename):
        return []
    try:
        with open(filename, "r", encoding="utf-8") as f:
            data = json.load(f)
            if isinstance(data, list):
                return data
            return []
    except (json.JSONDecodeError, OSError):
        return []


def save_facts(facts, filename: str = QUOTES_FILE):
    """å°‡äº‹å¯¦åˆ—è¡¨å­˜å› JSON æª”æ¡ˆã€‚"""
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(facts, f, ensure_ascii=False, indent=2)


def normalize_text(s: str) -> str:
    """ç”¨æ–¼æ¯”å°é‡è¤‡çš„ç°¡å–®æ­£è¦åŒ–ï¼šå»é™¤å‰å¾Œç©ºç™½ä¸¦ä½¿ç”¨å–®ä¸€ç©ºç™½ã€‚"""
    if not isinstance(s, str):
        return ""
    # ç°¡å–®è¦å‰‡ï¼šstrip + æŠŠé€£çºŒç©ºç™½å£“æˆå–®ä¸€ç©ºç™½
    return " ".join(s.strip().split())


def add_fact_if_unique(fact_text: str, source: str | None, filename: str = QUOTES_FILE):
    """å¦‚æœ fact_text å°šæœªå­˜åœ¨æª”æ¡ˆä¸­ï¼Œå‰‡æ–°å¢ä¸¦å„²å­˜ã€‚

    å›å‚³ï¼š
    - (True, entry)  è¡¨ç¤ºæ–°å¢æˆåŠŸ
    - (False, entry) è¡¨ç¤ºå·²å­˜åœ¨ï¼ˆä¸æ–°å¢ï¼‰ï¼Œentry ç‚ºæ—¢æœ‰æˆ–å»ºè­°çµæ§‹
    """
    facts = load_facts(filename)
    existing_texts = {normalize_text(item.get("text", "")) for item in facts}
    key = normalize_text(fact_text)

    entry = {
        "text": fact_text,
        "source": source,
        "added_at": datetime.now(timezone.utc).isoformat()
    }

    if key in existing_texts:
        return False, entry

    facts.append(entry)
    save_facts(facts, filename)
    return True, entry


def fetch_fact(url=API_URL, timeout=TIMEOUT, retries=RETRIES):
    """Fetch a single random fact from the API.

    Returns a tuple (fact_text, source_url) or (None, None) on failure.
    """
    # é è¨­æƒ…æ³ä¸‹ï¼Œä½¿ç”¨ certifi çš„ CA å¥—ä»¶
    # åƒ…é™é–‹ç™¼ï¼šè¨­ç½®ç’°å¢ƒè®Šé‡ DEBUG_SKIP_SSL=1 ä»¥å…è¨±æœªç¶“é©—è­‰çš„å›é€€ã€‚
    allow_unverified = os.environ.get("DEBUG_SKIP_SSL", "0") == "1"
    ctx = None
    if allow_unverified:
        ctx = ssl._create_unverified_context()
    else:
        ctx = ssl.create_default_context(cafile=certifi.where())

    attempt = 0
    while attempt <= retries:
        try:
            req = Request(url, headers={"User-Agent": "python-quote-collector/1.0"})
            with urlopen(req, timeout=timeout, context=ctx) as resp:
                raw = resp.read().decode("utf-8")
                data = json.loads(raw)

                # The API returns fields like 'text' and 'permalink'
                fact = data.get("text") or data.get("fact")
                permalink = data.get("permalink") or data.get("source_url")
                return fact, permalink

        except HTTPError as e:
            print(f"âš ï¸ HTTP error: {e.code} {e.reason}")
            return None, None
        except URLError as e:
            msg = str(e)
            print(f"âš ï¸ URL error / network issue: {msg}")
        except json.JSONDecodeError:
            print("âš ï¸ Failed to decode JSON from API response")
            return None, None

        attempt += 1
        if attempt <= retries:
            time.sleep(1)

    return None, None


def run_once():
    print("ğŸ” Fetching a random fact from uselessfacts.jsph.pl...")

    # æ”¯æ´ä»¥ç’°å¢ƒè®Šæ•¸è¦†å¯«ï¼Œæ–¹ä¾¿æ¸¬è©¦é‡è¤‡æª¢æŸ¥
    override_text = os.environ.get("FACT_OVERRIDE_TEXT")
    override_link = os.environ.get("FACT_OVERRIDE_LINK")

    if override_text:
        fact, link = override_text, override_link
    else:
        fact, link = fetch_fact()

    if not fact:
        print("\nâŒ Failed to retrieve a fact. Please check your network or try again later.")
        return False

    print("\nâ€” Random Fact â€”")
    print(fact)
    if link:
        print(f"\nSource: {link}")

    # å°‡å–å¾—çš„äº‹å¯¦å¯«å…¥æœ¬æ©Ÿå­˜æª”ï¼ˆé¿å…é‡è¤‡ï¼‰
    created, _ = add_fact_if_unique(fact, link, QUOTES_FILE)
    if created:
        print(f"\nâœ… Added to {QUOTES_FILE}. Total size may have increased.")
    else:
        print(f"\nğŸŸ¡ Duplicate detected. No changes to {QUOTES_FILE}.")
    return True


def main(argv=None):
    parser = argparse.ArgumentParser(description="Digital Fact Collector")
    parser.add_argument("--loop", action="store_true", help="æŒçºŒé‹è¡Œï¼Œä»¥å›ºå®šé–“éš”æŠ“å–æ–°äº‹å¯¦")
    parser.add_argument("--interval", type=int, default=600, help="å¾ªç’°æ¨¡å¼ä¸‹çš„æŠ“å–é–“éš”ç§’æ•¸ï¼ˆé è¨­ 600 ç§’ï¼‰")
    parser.add_argument("--max-runs", type=int, default=0, help="å¾ªç’°æ¨¡å¼ä¸‹æœ€å¤šåŸ·è¡Œæ¬¡æ•¸ï¼ˆ0 è¡¨ç¤ºç„¡é™ï¼‰")
    args = parser.parse_args(argv)

    if not args.loop:
        ok = run_once()
        sys.exit(0 if ok else 1)

    # è¿´åœˆæ¨¡å¼
    print(f"â±ï¸ Loop mode: interval={args.interval}s, max_runs={'âˆ' if args.max_runs == 0 else args.max_runs}")
    runs = 0
    try:
        while True:
            runs += 1
            print(f"\n=== Run {runs} @ {datetime.now(timezone.utc).isoformat()} ===")
            ok = run_once()
            if not ok:
                print("âš ï¸ This run failed to fetch a fact.")

            if args.max_runs and runs >= args.max_runs:
                print("âœ… Reached max_runs. Exiting loop.")
                break

            time.sleep(max(1, args.interval))
    except KeyboardInterrupt:
        print("\nğŸ›‘ Interrupted by user. Exiting loop.")
    sys.exit(0)


if __name__ == "__main__":
    main()
